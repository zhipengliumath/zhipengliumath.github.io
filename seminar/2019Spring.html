<html>
    <head>
        <title>KU Probability and Statistics Seminar (2019 Spring)
        </title>
    </head>
</html>

<body>
 <style type="text/css">.hidden{
    display:none;
}
.unhidden{
    display:block;
}
</style>
<style>
      table,
      th,
      td {
        padding: 10px;
        border: 1px solid black;
        border-collapse: collapse;
      }
    </style>
    
<script type="text/javascript">
    function unhide(divID, otherDivId) {
    var item = document.getElementById(divID);
    if (item) {
            item.className=(item.className=='hidden')?'unhidden':'hidden';
        }
        document.getElementById(otherDivId).className = 'hidden';
    }
</script>
<p><span style="font-size: 30px;">KU Probability and Statistics Seminar (Spring 2019)</span></p>

<p><span style="font-size:20px;">The seminars were held on Wednesdays 4pm-5pm at Snow 306. &nbsp;
 </span></p>
<p><span style="font-size:20px;">
 <a href="https://zhipengliumath.github.io/seminar">Seminar website</a>&nbsp;&nbsp;&nbsp; <a href="https://zhipengliumath.github.io">Homepage</a></span></p>

<table  style="width:75%">
	<tbody>
		<tr>
			<th style="width: 10%; font-size:20px;"><b>Date</b></th>
			<th><span style="width:90%; font-size:20px;">Title/Abstract</span></th>
		</tr>
		<tr>
			<td style="width: 5px;"><span style="font-size:20px;">February 21 (Smith Colloquium)</span></td>
			<td style="width: 20px;">
			<p><span style="font-size:20px;"><strong><a href="https://www.math.arizona.edu/~sethuram/">Sunder Sethuraman</a></strong> (University of Arizona)</span></p>

			<p><span style="font-size:22px;"><a class="button" href="javascript:unhide('Seth', 'link')"><em>On Hydrodynamic Limits of Young Diagrams</em></a></span></p>

			<div class="hidden" id="Seth" style="font-size: 20px">
			<div class="content3">
			<p>We consider a family of stochastic models of evolving two-dimensional Young diagrams, given in terms of certain energies, with Gibbs invariant measures.  `Static' scaling limits of the shape functions, under these Gibbs measures, have been much studied over the years.  In this talk, we discuss corresponding `dynamical' limits which are less understood.  We show that the hydrodynamic scaling limits of the Young diagram shape functions may be described by different types parabolic PDEs, depending on the energy structure.
</p>
			</div>
			</div>
			</td>
		</tr>
				<tr>
			<td style="width: 5px;"><span style="font-size:20px;">February 28 (Smith Colloquium)</span></td>
			<td style="width: 20px;">
			<p><span style="font-size:20px;"><strong><a href="https://lpetrov.cc/">Leonid Petrov</a></strong> (University of Virginia)</span></p>

			<p><span style="font-size:22px;"><a class="button" href="javascript:unhide('Petrov', 'link')"><em>From infinite random matrices over finite fields to square ice</em></a></span></p>

			<div class="hidden" id="Petrov" style="font-size: 20px">
			<div class="content3">
			<p>Asymptotic representation theory of symmetric groups is a rich and beautiful subject with deep connections with probability, mathematical physics, and algebraic combinatorics. A one-parameter deformation of this theory related to infinite random matrices over a finite field leads to a randomization of the classical Robinson-Schensted correspondence between words and Young tableaux. Exploring such randomizations we find unexpected applications to six vertex (square ice) type models and traffic systems on a 1-dimensional lattice.
</p>
			</div>
			</div>
			</td>
		</tr>
				<tr>
			<td style="width: 5px;"><span style="font-size:20px;">May 9 (Smith Colloquium)</span></td>
			<td style="width: 20px;">
			<p><span style="font-size:20px;"><strong><a href="http://web.math.princeton.edu/~jiequnh/">Jiequn Han</a></strong> (Princeton University)</span></p>

			<p><span style="font-size:22px;"><a class="button" href="javascript:unhide('Han', 'link')"><em>A Mean-Field Optimal Control Formulation of Deep Learning</em></a></span></p>

			<div class="hidden" id="Han" style="font-size: 20px">
			<div class="content3">
			<p>Recent work linking deep neural networks and dynamical systems opened up new avenues to analyze deep learning. In particular, it is observed that new insights can be obtained by recasting deep learning as an optimal control problem on difference or differential equations. However, the mathematical aspects of such a formulation have not been systematically explored. This talk introduces the mathematical formulation of the population risk minimization problem in deep learning as a mean-field optimal control problem. Mirroring the development of classical optimal control, we state and prove optimality conditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type. These mean-field results reflect the probabilistic nature of the learning problem. In addition, by appealing to the mean-field Pontryagin's maximum principle, we establish some quantitative relationships between population and empirical learning problems. This serves to establish a mathematical foundation for investigating the algorithmic and theoretical connections between optimal control and deep learning.</p>
			</div>
			</div>
			</td>
		</tr>

	</tbody>
</table>
</body>
