<html>
    <head>
        <title>KU Probability and Statistics Seminar (2022 Spring)
        </title>
    </head>
</html>

<body>
 <style type="text/css">.hidden{
    display:none;
}
.unhidden{
    display:block;
}
</style>
<style>
      table,
      th,
      td {
        padding: 10px;
        border: 1px solid black;
        border-collapse: collapse;
      }
    </style>
    
<script type="text/javascript">
    function unhide(divID, otherDivId) {
    var item = document.getElementById(divID);
    if (item) {
            item.className=(item.className=='hidden')?'unhidden':'hidden';
        }
        document.getElementById(otherDivId).className = 'hidden';
    }
</script>
<p><span style="font-size: 30px;">KU Probability and Statistics Seminar (Spring 2022)</span></p>

<p><span style="font-size:20px;">The seminars are held online using Zoom on Wednesdays 4pm-5pm. We may provide in-person seminars if the speaker prefers. </span></p>
<p><span style="font-size:20px;">If you are interested in giving a talk, please contact <a href="https://zhipengliumath.github.io">Zhipeng Liu</a> or <a href="https://people.ku.edu/~j139p002/">Joonha Park.</a> </span></p>
<p><span style="font-size:20px;">
 <a href="https://zhipengliumath.github.io/seminar">Seminar website</a>&nbsp;&nbsp;&nbsp; <a href="https://zhipengliumath.github.io">Homepage</a></span></p>


<table  style="width:75%">
	<tbody>
		<tr>
			<th style="width: 10%; font-size:20px;"><b>Date</b></th>
			<th><span style="width:90%; font-size:20px;">Title/Abstract</span></th>
		</tr>
		<tr>
			<td style="width: 3px;"><span style="font-size:14px;">Feb 16  (<b>2pm-3pm</b>)</span></td>
			<td style="width: 20px;"><p><span><strong><a href="https://sites.google.com/view/mustazee">Mustazee Rahman</a></strong> (Durham University)</span></p>
			<p><span style="font-size:16px;"><a class="button" href="javascript:unhide('Rahman', 'link')"><em>Characteristic of a second class particle</em></a></span></p>
			<div class="hidden" id="Rahman" style="font-size: 14px">
			<div class="content3">
			<p>The totally asymmetric simple exclusion process (TASEP) is a microscopic analogue of Burgers equation. The characteristics of Burgers equation play an important role in its solution. The second class particle in TASEP mirrors the role of a microscopic characteristic. Although much is known about the macroscopic behaviour of the second class particle, it is of interest to understand its fluctuations. I will discuss the behaviour of the second class particle when the initial conditions of TASEP converge under KPZ scaling. The second class particle has a scaling limit, which can be described in terms of geometric concepts arising in the KPZ universality class. This is joint work with Balint Virag.</p>
			</div>
			</div>
			</td>
		</tr>
		<tr>
			<td style="width: 3px;"><span style="font-size:14px;">Feb 23</span></td>
			<td style="width: 20px;"><p><span><strong><a href="https://math.temple.edu/~tue86896/">Brian Rider
</a></strong> (Temple University)</span></p>
<p><span style="font-size:16px;"><a class="button" href="javascript:unhide('Rider', 'link')"><em>A general beta crossover ensemble</em></a></span></p>
			<div class="hidden" id="Rider" style="font-size: 14px">
			<div class="content3">
			<p>The general beta analogues of the Gaussian Orthogonal, Unitary, and Symplectic Ensembles (for which beta = 1, 2, or 4) are now understood to posses all standard local limit laws described in terms certain random differential operators. Of great interest though in random matrix theory are so-called double scaling limits, tied to irregular points in the limiting spectrum. Outside of beta = 2 (and to lesser extents 1 and 4) very little progress has been made in this direction. Here I'll present a random operator description for a particular general beta ensemble in the window where the “hard” and “soft” edges of the spectrum meet. (Based on joint work with J. Ramirez - Univ. Costa Rica.)</p>
			</div>
			</div>
			</td>
		</tr>
		<tr>
			<td style="width: 3px;"><span style="font-size:14px;">Mar 2</span><td style="width: 20px;"><p><span><strong><a href="https://mathematics.ku.edu/people/mehmet-yenisey">Mehmet Yenisey
</a></strong> (University of Kansas)</span></p>
			</td>
		</tr>
		<tr>
			<td style="width: 3px;"><span style="font-size:14px;">Apr 27</span></td>
			<td style="width: 20px;"><p><span><strong><a href="https://math.temple.edu/~tuk46087/">Atilla Yilmaz
</a></strong> (Temple University)</span></p><p><span style="font-size:16px;"><a class="button" href="javascript:unhide('Yilmaz', 'link')"><em>Stochastic homogenization of viscous Hamilton-Jacobi equations in one dimension</em></a></span></p>
			<div class="hidden" id="Yilmaz" style="font-size: 14px">
			<div class="content3">
			<p>After giving a general and self-contained introduction to the homogenization of Hamilton-Jacobi (HJ) equations, including the classical results in the cases where the Hamiltonian is periodic in the spatial variable $x$ or convex in the gradient variable $p$, I will focus on viscous HJ equations in one space dimension with separable Hamiltonians of the form $G(p) + V(x,\omega)$, where $G$ is a nonconvex function and $V$ is a stationary & ergodic random potential that satisfies a valley & hill condition (which holds in many natural examples, but fails in the periodic case). I will present several recent results on this class of HJ equations (by various combinations of A. Davini, E. Kosygina, O. Zeitouni and myself), where homogenization is established by showing that, outside of the intervals where the effective Hamiltonian turns out to be flat (due to the valley & hill condition), there is a unique sublinear corrector (which is a notion I will introduce) with certain properties. In the special case where $G$ is the minimum of two identical parabolas, these sublinear correctors have convenient representations involving Brownian motion in a random potential. More generally, the existence & uniqueness of these sublinear correctors can be proved using ODE methods that bypass the need for explicit representations, which I will demonstrate when $G$ is quasiconvex.
</p>
			</div>
			</div>
			</td>
		</tr>
		<tr>
			<td style="width: 3px;"><span style="font-size:14px;">May 4</span></td>
			<td style="width: 20px;"><p><span><strong><a href="https://web.mst.edu/~huwen/">Wenqing Hu
</a></strong> (Missouri University of Science and Technology )</span></p>
<p><span style="font-size:16px;"><a class="button" href="javascript:unhide('Hu', 'link')"><em>On the Posterior Distribution of a Random Process Conditioned on Observing the Empirical Frequencies: the i.i.d and finite Markov chain case</em></a></span></p>
			<div class="hidden" id="Hu" style="font-size: 14px">
			<div class="content3">
			<p>We consider here the question of recovering the posterior distribution of a random process conditioned on observing the empirical frequencies of the outcomes. We find that, under a rather broad assumption of the dependence structure of the process, such as ``independence"; or ``Markovian dependence";, the posterior marginal distribution of the process at a given time index can be identified as some empirical distribution calculated from the observed empirical frequencies of the process' outcomes. We show by two examples including the i.i.d. sequence with discrete values and a finite Markov chain, that a certain ``conditional symmetry" given by the observation of the empirical frequencies leads to the desired posterior distribution result. Our results are about finite-time observations, and we further investigate its infinite-time limit
connecting with the idea of Gibbs conditioning. Finally, since our results demonstrate the importance of empiricial frequency in understanding the information behind data, we use the Large Deviations Principle (LDP) to construct a general notion of ``data-driven entropy", from which we can apply the formalism of thermodynamics to data sciences. The talk is based on joint work with Professor Hong Qian.
</p>
			</div>
			</div>
			</td>
		</tr>
	</tbody>
</table>
</body>

